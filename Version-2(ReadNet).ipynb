{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hanker --> 0\n",
    "#n-95 --> 1\n",
    "#no_mask --> 2\n",
    "#threelayer --> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 240)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "import PIL\n",
    "import PIL.Image, PIL.ImageTk\n",
    "import numpy as np\n",
    "from tkinter.ttk import *\n",
    "from tkinter import *\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "loop = False\n",
    "loop2 = False\n",
    "class Runner(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        container = tk.Frame(self)\n",
    "\n",
    "        container.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "        self.frames = {}\n",
    "\n",
    "        frame = StartPage(container, self)\n",
    "\n",
    "        self.frames[StartPage] = frame\n",
    "        frame.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        self.show_frame(StartPage)\n",
    "\n",
    "    def show_frame(self, cont):\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "        \n",
    "class StartPage(tk.Frame):\n",
    " \n",
    "    def __init__(self, window, controller, video_source=0):\n",
    "        tk.Frame.__init__(self,window)\n",
    "        self.video_source = video_source\n",
    "        self.controller = controller\n",
    "        cam_frame = tk.Frame(self)\n",
    "        self.vid = MyVideoCapture(self.video_source)\n",
    "        self.stop_camera()\n",
    "        self.canvas = tk.Canvas(cam_frame, width = self.vid.width-3, height = self.vid.height-3,bg=\"black\",bd=2)\n",
    "        self.delay = 15\n",
    "        self.canvas.pack(padx=5,pady=5)\n",
    "        cam_frame.pack(side=\"left\",anchor=\"nw\")\n",
    "        self.center_coordinates = (int(self.vid.width//2),int(self.vid.height//2)) \n",
    "        print(self.center_coordinates)\n",
    "        self.radius = int(self.vid.height//3)\n",
    "        self.font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        self.Blue = (0, 0, 255)\n",
    "        self.Red =  (255,0,0)\n",
    "        self.Green = (0,255,0)\n",
    "        self.Black = (0,0,0)\n",
    "        self.thickness = 2\n",
    "        self.org = ((self.vid.width//2)-100, self.vid.height-25) \n",
    "        self.fontScale = 1\n",
    "        self.maskNet = load_model(\"mask_type.h5\")\n",
    "        prototxtPath = os.path.sep.join([\"face_detector\", \"deploy.prototxt\"])\n",
    "        weightsPath = os.path.sep.join([\"face_detector\",\"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "        self.faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "        self.counter = 0\n",
    "        self.start_camera()\n",
    "        \n",
    "    def detect_and_predict_mask(self,frame):\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),(104.0, 177.0, 123.0))\n",
    "        self.faceNet.setInput(blob)\n",
    "        detections = self.faceNet.forward()\n",
    "        faces = []\n",
    "        locs = []\n",
    "        preds = []\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > .2:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                face = frame[startY:endY, startX:endX]\n",
    "                if face.shape[0] > 0 and face.shape[1] > 0:\n",
    "                    face = cv2.resize(face, (224, 224))\n",
    "                    faces.append(face)\n",
    "                    locs.append((startX, startY, endX, endY))\n",
    "        return (len(faces),locs)\n",
    "        \n",
    "    def update(self):\n",
    "        try:\n",
    "            global loop\n",
    "            if loop:\n",
    "                x,y,w,h = self.center_coordinates[0]-self.radius,self.center_coordinates[1]-self.radius,2*self.radius,2*self.radius\n",
    "                self.ret, self.frame = self.vid.get_frame()\n",
    "                frame2 = self.frame[y:y+h,x:x+w,:].copy()\n",
    "                Numfaces,locs = self.detect_and_predict_mask(frame2)\n",
    "                if Numfaces >= 1:\n",
    "                    (startX, startY, endX, endY) = locs[0]\n",
    "                    if abs(endX-startX) > ((w//2)) and abs(endY-startY) > ((h//2)):\n",
    "                        cc = self.Green\n",
    "                        lst = [\"Cotton_Mask\",\"N-95_Mask\",\"No_Mask\",\"Three_Layer_Mask\"]\n",
    "                        img = cv2.resize(frame2,(224,224))/255.0\n",
    "                        pred = self.maskNet.predict(img.reshape(1,224,224,3))\n",
    "                        label = lst[np.argmax(pred)]\n",
    "                        coor = (self.center_coordinates[0]-(len(label)*8),self.frame.shape[0]-10)\n",
    "                        self.frame = cv2.putText(self.frame,label,coor,cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),1,cv2.LINE_AA)\n",
    "                        self.frame = cv2.putText(self.frame,\"Correct\",(self.center_coordinates[0]-50,self.center_coordinates[1]),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),1,cv2.LINE_AA)\n",
    "                    else:\n",
    "                        cc = self.Red\n",
    "                        self.frame = cv2.putText(self.frame,\"To Far From Screen\",(self.center_coordinates[0]-158,self.center_coordinates[1]),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),1,cv2.LINE_AA)\n",
    "                else:\n",
    "                    cc = self.Black\n",
    "                self.frame = cv2.circle(self.frame, self.center_coordinates, self.radius, cc, self.thickness)\n",
    "                if self.ret:\n",
    "                    self.photo = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(self.frame))\n",
    "                    self.canvas.create_image(0, 0, image = self.photo, anchor = tk.NW)\n",
    "                    self.after(self.delay, self.update)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Restart Application\")\n",
    "            self.stop_camera()\n",
    "    \n",
    "    def stop_camera(self):\n",
    "        global loop\n",
    "        if loop:\n",
    "            loop = False\n",
    "            self.vid.stop_video_capture()\n",
    "            self.canvas.delete(\"all\")\n",
    "            \n",
    "    def start_camera(self):\n",
    "        global loop\n",
    "        if not loop:\n",
    "            loop = True\n",
    "            self.vid.start_video_capture()\n",
    "            self.update()\n",
    "class MyVideoCapture:\n",
    "    \n",
    "    def __init__(self, video_source=0):\n",
    "        self.video_source = video_source\n",
    "        self.vid1 = cv2.VideoCapture(self.video_source)\n",
    "        if not self.vid1.isOpened():\n",
    "             raise ValueError(\"Unable to open video source\", video_source)\n",
    "        self.width = self.vid1.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        self.height = self.vid1.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        \n",
    "    def start_video_capture(self):\n",
    "        if not self.vid1.isOpened():\n",
    "            print(\"start_video_capture\")\n",
    "            self.vid1 = cv2.VideoCapture(self.video_source)\n",
    "      \n",
    "    def stop_video_capture(self):\n",
    "        if self.vid1.isOpened():\n",
    "            print(\"stop_video_capture\")\n",
    "            self.vid1.release()\n",
    "                \n",
    "    def get_frame(self):  \n",
    "        if self.vid1.isOpened():\n",
    "            ret, frame = self.vid1.read()\n",
    "            if ret:\n",
    "                return (ret, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                return (ret, None)\n",
    "\n",
    "app = Runner()\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'tuple' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8fa46e16a00b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tuple' and 'tuple'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
